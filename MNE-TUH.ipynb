{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temple University Dataset\n",
    "\n",
    "The Temple University Dataset is a large, open-access, dataset of clincal EEG data. \n",
    "\n",
    "Web link: https://www.isip.piconepress.com/projects/tuh_eeg/html/overview.shtml\n",
    "\n",
    "Paper Overview: http://journal.frontiersin.org/article/10.3389/fnins.2016.00196/full\n",
    "\n",
    "Ultimately, the goal will be to use this dataset, which is on a scale never really seen before in EEG datasets, to try and characterize and understand brain activity in a large cohort, across 'normal' brain activity, and disease. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASKS:\n",
    "The first set of tasks relates to working on a pre-processing pipeline for the data. Regardless of the set of analyses we ultimately choose, the data need to be organized, cleaned and pre-processed in such a way that we have confidence that the analyses we run reflect brain activity, not artifacts. A key goal of setting up this pipeline is that it be automatic and robust - given the number of subjects, we need to have confidence we can run this pipeline without manual supervision, and trust the data that comes out of it. \n",
    "\n",
    "Note: since we're using MNE, we don't want to end up with some information inside the MNE objects, and some outside them. As we develop these processes, let's try to keep a tight integration with MNE. \n",
    "\n",
    "### First Goal:\n",
    "    - Fully clean a subject of the rest state, for example, run the PSD over the remaining channels, and trust it reflects brain activity.\n",
    "\n",
    "### Preprocessing Tasks\n",
    "Pre-processing pipeline:\n",
    "  - Sort out the channel names and data types. \n",
    "      - Target output: a list of just the standard channel names (example: FP1, Cz, T4)\n",
    "          - Also: Keep track of channel types. (Another list of ['EEG', 'EEG', 'EMG'])\n",
    "              - Then: make sure we can put this 'back' into the MNE objects - update the channel info accordingly. \n",
    "  - What are the event markers? How do we line them up with the data? Can we epoch into different 'states'?\n",
    "      - Target output: extracted epoch of resting data. \n",
    "  - How can we (automatically?) reject bad channels\n",
    "      - We want to figure out MNE's available tools to reject channels, and start applying them.\n",
    "      - Target output: For example subjects, channels we don't trust (visually) should be able to be 'dropped' (marked as bad so that they are ignored by future processing) by running an automatic process. \n",
    "  - How can we (automatically?) reject bad time segments\n",
    "      - We want to figure out MNE's available tools to reject time segments, and start applying them.\n",
    "      - Target output: For example subjects, time segments we don't trust (visually) should be dropped (again, marked bad to be ignored) by running an automatic process. \n",
    "  - How can we (automatically?) deal with stereotyped artifacts - such as eye blinks, heartbeats, saccades\n",
    "      - Here I mean artifacts that we can correct for, different from time segments we decide we need to avoid.\n",
    "      - We want to figure out MNE's available tools to correct for artifacts, and start applying them.\n",
    "      - Target output: This depends slightly more on what is available (in the data, and in MNE), but ideally, for heartbeat and eye blinks (perhaps others), we would like to be able to automatically label them and 'subtract' them out from the data in some way - such that we can keep, and still use, these segments of data. \n",
    "      \n",
    "Final outcome: A cleaned segment of resting data, ready for analysis, for 1 or 2 subjects. Working through this process will be very manually supervised, but hopefully by the time it's finished, the whole process can be re-run automatically, without human input, and this process can also be applied to other subjects. \n",
    "  \n",
    "### Database Work (2nd level of task)\n",
    "We will need utility functions to work with the database, to list subjects, find subjects, get paths, etc. \n",
    "- We'll work on this mainly when we want to scale up the number of subjects. Don't start it yet, I have some example code from other projects that can form a basis of this. \n",
    "\n",
    "\n",
    "### Metadata Work (3rd level of task)\n",
    "Ultimately, we probably want some tools to be able to automatically scrape the clinical notes, and extract key parameters, like age, sex, and diagnoses. \n",
    "- This is not an immediate priority, as it will become more relevant as we fine-tune the analyses. We might, for example, start with the clearly labelled 'epilepsy vs non-epilepsy' group that is available, before we try to do large-scale mining of the clinical notes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "- This first level of work is very pre-process-y, but required to get started with this data. Once we have a couple subjects set up with something that works at least reasonably well, we'll move on to more analysis stuff, and really get into the data, so that we're not stuck forever on pre-processing. \n",
    "- The goal is to get a rough version of the full pipeline, allowing us to 'see' the whole project, and find any major hurdles. It also, in practice, lets us try out each part of the project first, without getting bogged down at any particular step. \n",
    "- Eventually, we will have to double back and make sure each step is really robust.\n",
    "- Also, soon, we will work a bit on setting up our codebase as a proper module, for organization and scalability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib qt\n",
    "import mne\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "\n",
    "# This base path will need updating\n",
    "base_path = 'C:\\\\Users\\\\Luyanda Mdanda\\\\Documents\\\\Research\\\\tuh_eeg'\n",
    "\n",
    "# These should stay the same\n",
    "#subj_dat_fname = 'tuh_eeg\\v0.2\\00000164\\00000164_0.edf'\n",
    "subj_dat_fname = 'tuh_eeg\\\\v0.2\\\\00000184\\\\00000184_0.edf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting edf Parameters from C:\\Users\\Luyanda Mdanda\\Documents\\Research\\tuh_eeg\\tuh_eeg\\v0.2\\00000184\\00000184_0.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# Read in an example subject of data (subject chosen randomly)\n",
    "full_path = os.path.join(base_path, subj_dat_fname)\n",
    "eeg_dat = mne.io.read_raw_edf(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EEG FP1-REF',\n",
       " 'EEG FP2-REF',\n",
       " 'EEG F3-REF',\n",
       " 'EEG F4-REF',\n",
       " 'EEG C3-REF',\n",
       " 'EEG C4-REF',\n",
       " 'EEG P3-REF',\n",
       " 'EEG P4-REF',\n",
       " 'EEG O1-REF',\n",
       " 'EEG O2-REF',\n",
       " 'EEG F7-REF',\n",
       " 'EEG F8-REF',\n",
       " 'EEG T3-REF',\n",
       " 'EEG T4-REF',\n",
       " 'EEG T5-REF',\n",
       " 'EEG T6-REF',\n",
       " 'EEG T1-REF',\n",
       " 'EEG T2-REF',\n",
       " 'EEG FZ-REF',\n",
       " 'EEG CZ-REF',\n",
       " 'EEG PZ-REF',\n",
       " 'EEG EKG1-REF',\n",
       " 'EEG A1-REF',\n",
       " 'EEG A2-REF',\n",
       " 'PHOTIC-REF',\n",
       " 'IBI',\n",
       " 'BURSTS',\n",
       " 'SUPPR',\n",
       " 'STI 014']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the info object for this subject\n",
    "eeg_dat.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'T1', 'T2', 'FZ', 'CZ', 'PZ', 'EKG', 'A1', 'A2', 'PHOTIC-REF', 'IBI', 'BURSTS', 'SUPPR', 'STI 014']\n",
      "The following EEG sensors did not have a position specified in the selected montage: ['FP1', 'FP2', 'T1', 'T2', 'FZ', 'CZ', 'PZ', 'EKG']. Their position has been left untouched.\n",
      "<Info | 15 non-empty fields\n",
      "    bads : 'list | 0 items\n",
      "    ch_names : 'list | FP1, FP2, F3, F4, C3, C4, P3, P4, O1, O2\n",
      "    chs : 'list | 29 items (STIM: 1, MISC: 4, EEG: 24)\n",
      "    comps : 'list | 0 items\n",
      "    custom_ref_applied : 'bool | False\n",
      "    dev_head_t : 'mne.transforms.Transform | 3 items\n",
      "    events : 'list | 0 items\n",
      "    highpass : 'float | 0.0 Hz\n",
      "    hpi_meas : 'list | 0 items\n",
      "    hpi_results : 'list | 0 items\n",
      "    lowpass : 'float | 128.0 Hz\n",
      "    meas_date : 'numpy.ndarray | 1969-12-31 16:00:00\n",
      "    nchan : 'int | 29\n",
      "    projs : 'list | 0 items\n",
      "    sfreq : 'float | 256.0 Hz\n",
      "    acq_pars : 'NoneType\n",
      "    acq_stim : 'NoneType\n",
      "    buffer_size_sec : 'NoneType\n",
      "    ctf_head_t : 'NoneType\n",
      "    description : 'NoneType\n",
      "    dev_ctf_t : 'NoneType\n",
      "    dig : 'NoneType\n",
      "    experimenter : 'NoneType\n",
      "    file_id : 'NoneType\n",
      "    filename : 'NoneType\n",
      "    hpi_subsystem : 'NoneType\n",
      "    kit_system_id : 'NoneType\n",
      "    line_freq : 'NoneType\n",
      "    meas_id : 'NoneType\n",
      "    proj_id : 'NoneType\n",
      "    proj_name : 'NoneType\n",
      "    subject_info : 'NoneType\n",
      "    xplotter_layout : 'NoneType\n",
      ">\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-4adc77a0006a>:42: RuntimeWarning: The following EEG sensors did not have a position specified in the selected montage: ['FP1', 'FP2', 'T1', 'T2', 'FZ', 'CZ', 'PZ', 'EKG']. Their position has been left untouched.\n",
      "  info = mne.create_info(channel_names, eeg_dat.info['sfreq'], channel_types, montage)\n"
     ]
    }
   ],
   "source": [
    "# Example of one way to start fixing up the channels\n",
    "#  Priority again is to keep everything consistent with MNE, so first check for MNE functions that can do \n",
    "#   things like this, and that can update this information insode the data.info object. \n",
    "\n",
    "\n",
    "channel_names = []\n",
    "channel_types =[]\n",
    "\n",
    "# lists to store the array names\n",
    "\n",
    "for ch in eeg_dat.ch_names:    \n",
    "    if 'EEG' in ch:\n",
    "        ch = ch[4:7]\n",
    "        ch =''.join(e for e in ch if e.isalnum())\n",
    "        channel_names.append(ch)\n",
    "        channel_types.append('eeg')\n",
    "        \n",
    "    elif 'EMG' in ch:\n",
    "        ch = ch[4:7]\n",
    "        ch =''.join(e for e in ch if e.isalnum())\n",
    "        channel_names.append(ch)\n",
    "        channel_types.append('emg')\n",
    "        # Keeps track that this is an EMG channels\n",
    "        \n",
    "    elif 'STI' in ch:\n",
    "        channel_names.append(ch)\n",
    "        channel_types.append('stim')\n",
    "        # Keeps track that this is an STI channel\n",
    "    \n",
    "    else:\n",
    "        channel_names.append(ch)\n",
    "        channel_types.append('misc')\n",
    "        # Keeps track of MISC channels\n",
    "        \n",
    "# The EEG channels use the standard naming strategy.\n",
    "# By supplying the 'montage' parameter, approximate locations\n",
    "montage = 'standard_1020'\n",
    "\n",
    "print (channel_names)\n",
    "\n",
    "\n",
    "info = mne.create_info(channel_names, eeg_dat.info['sfreq'], channel_types, montage)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Info | 17 non-empty fields\n",
       "    bads : 'list | 0 items\n",
       "    buffer_size_sec : 'float | 1.0\n",
       "    ch_names : 'list | EEG FP1-REF, EEG FP2-REF, EEG F3-REF, EEG F4-REF, ...\n",
       "    chs : 'list | 29 items (STIM: 1, EEG: 28)\n",
       "    comps : 'list | 0 items\n",
       "    custom_ref_applied : 'bool | False\n",
       "    dev_head_t : 'mne.transforms.Transform | 3 items\n",
       "    events : 'list | 0 items\n",
       "    filename : 'str | C:\\Users\\L.../00000184_0.edf\n",
       "    highpass : 'float | 0.0 Hz\n",
       "    hpi_meas : 'list | 0 items\n",
       "    hpi_results : 'list | 0 items\n",
       "    lowpass : 'float | 128.0 Hz\n",
       "    meas_date : 'int | 1357041778\n",
       "    nchan : 'int | 29\n",
       "    projs : 'list | 0 items\n",
       "    sfreq : 'float | 256.0 Hz\n",
       "    acq_pars : 'NoneType\n",
       "    acq_stim : 'NoneType\n",
       "    ctf_head_t : 'NoneType\n",
       "    description : 'NoneType\n",
       "    dev_ctf_t : 'NoneType\n",
       "    dig : 'NoneType\n",
       "    experimenter : 'NoneType\n",
       "    file_id : 'NoneType\n",
       "    hpi_subsystem : 'NoneType\n",
       "    kit_system_id : 'NoneType\n",
       "    line_freq : 'NoneType\n",
       "    meas_id : 'NoneType\n",
       "    proj_id : 'NoneType\n",
       "    proj_name : 'NoneType\n",
       "    subject_info : 'NoneType\n",
       "    xplotter_layout : 'NoneType\n",
       ">"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_dat.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
